{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 🏎 Formula 1 'Hybrid Era' Analysis\n",
    "\n",
    "<img src=\"notebook_source/JPG-RGB-F1_70_Number_HotRed_Standard_RGB-1024x302.jpg\">\n",
    "\n",
    "### About the Dataset\n",
    "\n",
    "#### Context\n",
    "\n",
    "Formula 1 (a.k.a. F1 or Formula One) is the highest class of single-seater auto racing sanctioned by the Fédération Internationale de l'Automobile (FIA) and owned by the Formula One Group. The FIA Formula One World Championship has been one of the premier forms of racing around the world since its inaugural season in 1950. The word \"formula\" in the name refers to the set of rules to which all participants' cars must conform. A Formula One season consists of a series of races, known as Grands Prix, which take place worldwide on purpose-built circuits and on public roads.\n",
    "\n",
    "#### Content\n",
    "\n",
    "The dataset consists of all information on the Formula 1 races, drivers, constructors, qualifying, circuits, lap times, pit stops, championships from 1950 till the latest 2021 season.\n",
    "\n",
    "## What is the Hybird Era?\n",
    "\n",
    "### 2014-2021\n",
    "\n",
    "The year 2014 ushered in the most significant rule changes in F1 history, with normally aspirated, 2.4-liter V8 engines replaced by new, 1.6-liter turbocharged V6 “power units” (no longer officially called engines) integrated with complex, hybrid energy recovery systems (ERS) that FIA claimed “gave the sport a much cleaner and greener image more relevant to developing road car technologies.”&#x20;\n",
    "\n",
    "The new formula allows turbocharged engines, which last appeared in 1988. These have their efficiency improved through turbo-compounding by recovering energy from exhaust gases. The original proposal for four-cylinder turbocharged engines was not welcomed by the racing teams, in particular Ferrari. A compromise was reached, allowing V6 forced induction engines instead. The engines rarely exceed 12,000 rpm during qualifying and race, due to the new fuel flow restrictions.\n",
    "\n",
    "Energy recovery systems such as KERS had a boost of 160 hp (120 kW) and 2 megajoules per lap. KERS was renamed Motor Generator Unit–Kinetic (MGU-K). Heat energyrecovery systems were also allowed, under the name Motor Generator Unit–Heat (MGU-H)\n",
    "\n",
    "The 2015 season was an improvement on 2014, adding about 30–50 hp (20–40 kW) to most engines, the Mercedes engine being the most powerful with 870 hp (649 kW). In 2019, Renault's engine was claimed to have hit 1,000 hp in qualifying trim.\n",
    "\n",
    "### 2022\n",
    "\n",
    "In 2017, the FIA began negotiations with existing constructors and potential new manufacturers over the next generation of engines with a projected introduction date of 2021 but delayed to 2022 due to the effects of the COVID-19 pandemic. The initial proposal was designed to simplify engine designs, cut costs, promote new entries and address criticisms directed at the 2014 generation of engines. It called for the 1.6 L V6 configuration to be retained, but abandoned the complex Motor Generator Unit–Heat (MGU-H) system. The Motor Generator Unit–Kinetic (MGU-K) would be more powerful, with a greater emphasis on driver deployment and a more flexible introduction to allow for tactical use.&#x20;\n",
    "\n",
    "The proposal also called for the introduction of standardised components and design parameters to make components produced by all manufacturers compatible with one another in a system dubbed \"plug in and play\". A further proposal to allow four-wheel drive cars was also made, with the front axle driven by an MGU-K unit—as opposed to the traditional driveshaft—that functioned independently of the MGU-K providing power to the rear axle, mirroring the system developed by Porsche for the 919 Hybrid race car.\n",
    "\n",
    "However, mostly due to no engine supplier applying for F1 entry in 2021 and 2022, abolishment of the MGU-H, a more powerful MGU-K and a four-wheel drive system were all shelved with the possibility of their re-introduction for 2026. Instead, the teams and FIA agreed to a radical change in body/chassis aerodynamics to promote more battles on the course at closer distances to each other. They further agreed to an increase in alcohol content from 5.75% to 10% of fuel, and to implement a freeze on power unit design for 2022-2025, with the ICE, turbocharger and MGU-H being frozen on March 1st and the energy store, MGU-K and control electronics being frozen on September 1st during the 2022 season. Honda, the outgoing engine supplier in 2021, was keen to keep the MGU-H, and Red Bull, who took over the engine production project, backed that opinion. The 4WD system was planned to be based on Porsche 919 Hybrid system, but Porsche ended up not becoming an F1 engine supplier for 2021-2022."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### How to run the code\n",
    "\n",
    "This is an executable [*Jupyter notebook*](https://jupyter.org) hosted on [Jovian.ml](https://www.jovian.ml), a platform for sharing data science projects. You can run and experiment with the code in a couple of ways: *using free online resources* (recommended) or *on your own computer*.\n",
    "\n",
    "#### Option 1: Running using free online resources (1-click, recommended)\n",
    "\n",
    "The easiest way to start executing this notebook is to click the \"Run\" button at the top of this page, and select \"Run on Binder\". This will run the notebook on [mybinder.org](https://mybinder.org), a free online service for running Jupyter notebooks. You can also select \"Run on Colab\" or \"Run on Kaggle\".\n",
    "\n",
    "\n",
    "#### Option 2: Running on your computer locally\n",
    "\n",
    "1. Install Conda by [following these instructions](https://conda.io/projects/conda/en/latest/user-guide/install/index.html). Add Conda binaries to your system `PATH`, so you can use the `conda` command on your terminal.\n",
    "\n",
    "2. Create a Conda environment and install the required libraries by running these commands on the terminal:\n",
    "\n",
    "```\n",
    "conda create -n zerotopandas -y python=3.8 \n",
    "conda activate zerotopandas\n",
    "pip install jovian jupyter numpy pandas matplotlib seaborn opendatasets --upgrade\n",
    "```\n",
    "\n",
    "3. Press the \"Clone\" button above to copy the command for downloading the notebook, and run it on the terminal. This will create a new directory and download the notebook. The command will look something like this:\n",
    "\n",
    "```\n",
    "jovian clone notebook-owner/notebook-id\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "4. Enter the newly created directory using `cd directory-name` and start the Jupyter notebook.\n",
    "\n",
    "```\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "You can now access Jupyter's web interface by clicking the link that shows up on the terminal or by visiting http://localhost:8888 on your browser. Click on the notebook file (it has a `.ipynb` extension) to open it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the Dataset\n",
    "\n",
    "We will be using pyergast to for access to the Formula 1 database provided by Ergast API. Pyergast gives us direct access to the database, with no need to downlowd a CSV or any other files. \n",
    "\n",
    "The \"explore_pyergast.py\" file will dive into pyergast's features and do some minor exploration in the data to gain familirity with the pyergast commands. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -upgrade pip -quiet\n",
    "%pip install pyergast -upgrade -quiet\n",
    "%pip install jovian -upgrade -quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyergast requires both numpy and pandas\n",
    "from __future__ import print_function\n",
    "\n",
    "import pprint as pp\n",
    "import jovian\n",
    "import sys\n",
    "from unittest import result\n",
    "import contextlib\n",
    "\n",
    "import fastf1\n",
    "import fastf1.plotting as plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from fastf1.core import Laps\n",
    "from IPython.utils import io\n",
    "from timple.timedelta import strftimedelta\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us save and upload our work to Jovian before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"hybrid-era-analysis\"\n",
    "project_file = \"Hybrid_Era_Analysis.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with contextlib.suppress(Exception):\n",
    "    jovian.commit(project=project_name, filename=project_file, files=[\"explore_ergast.py\", \"notebook_source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation and Cleaning\n",
    "\n",
    "**TODO** - Write some explanation here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Instructions (delete this cell):\n",
    ">\n",
    "> - Load the dataset into a data frame using Pandas\n",
    "> - Explore the number of rows & columns, ranges of values etc.\n",
    "> - Handle missing, incorrect and invalid data\n",
    "> - Perform any additional steps (parsing dates, creating additional columns, merging multiple dataset etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DATA PREPARATION\n",
    "class FormulaOneDataPreper:\n",
    "    def __init__(self, start, end, cache=True):\n",
    "        # SPECIFIED YEARS THAT WILL BE PREPPED\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "\n",
    "        self.hybrid_schs = {}\n",
    "        self.events = {}\n",
    "        self.event_data = {}\n",
    "\n",
    "        # CHECK IF CACHE IS ENABLED\n",
    "        if cache:\n",
    "            fastf1.Cache.enable_cache('./cache')   # optional but recommended\n",
    "\n",
    "    \"\"\"\n",
    "    Retrive the event schedule for the years specified in the constructor.\n",
    "    If no years are specified, the schedule for all years (start - end) will be retrieved.\n",
    "    \"\"\"\n",
    "    def get_schs(self, **kwargs):\n",
    "        year = kwargs.get('year')\n",
    "\n",
    "        if year is None:\n",
    "            # NO YEAR REQUESTED, FALL BACK TO  START AND END VALUES\n",
    "            for i in range(self.start, self.end):\n",
    "                self.hybrid_schs[i] = fastf1.get_event_schedule(i, include_testing=False)\n",
    "        elif year in range(self.start, self.end):\n",
    "            # YEAR REQUESTED IS WITHIN THE DATA RANGE\n",
    "            self.hybrid_schs[year] = fastf1.get_event_schedule(year, include_testing=False)\n",
    "        else:\n",
    "            # YEAR REQUESTED IS OUTSIDE THE DATA RANGE\n",
    "            print (f\"Year {year} is outside of the data range {self.start} - {self.end}\")\n",
    "    \"\"\"\n",
    "    Pull all events from schedules and store them in a dictionary. {year: [events]}\n",
    "    THIS MIGHT BE REDUNDANT AND UNNECESSARY\n",
    "    \"\"\"\n",
    "    def get_events(self, **kwargs):\n",
    "        year = kwargs.get('year')\n",
    "        event = kwargs.get('event')\n",
    "\n",
    "        if year is None and event is None:\n",
    "            # NO YEAR OR EVENT SPECIFIED, GET ALL EVENTS FOR ALL PREPPED YEARS\n",
    "            for i in range(self.start, self.end):\n",
    "                self.events[i] = list(self.hybrid_schs[i]['EventName'])\n",
    "        elif year is None:\n",
    "            # NO YEAR SPECIFIED, GET ALL EVENTS FOR THE SPECIFIED EVENT\n",
    "            # CURRENTLY NOT IMPLEMENTED\n",
    "            return f\"Year not specified for event {event}\"\n",
    "        elif event is None:\n",
    "            # NO EVENT SPECIFIED, GET ALL EVENTS FOR THE SPECIFIED YEAR\n",
    "            self.events[year] = list(self.hybrid_schs[year]['EventName'])\n",
    "        else:\n",
    "            # SPECIFIED YEAR AND EVENT, GET THE SPECIFIED EVENT\n",
    "            try:\n",
    "                year in self.hybrid_schs[year]\n",
    "            except Exception:\n",
    "                # SINGLE YEAR REQUESTED IS OUTSIDE THE DATA RANGE\n",
    "                print(f\"Year {year} is outside of the data range {self.start} - {self.end}\")\n",
    "            else:\n",
    "                if event in list(self.hybrid_schs[year]['EventName']):\n",
    "                    self.events[year] = event\n",
    "                else:\n",
    "                    print(f\"Event {event} not found in year {year}\")\n",
    "\n",
    "    \"\"\"\n",
    "    Collect the data for the specified years and events and or sessions.\n",
    "    Defaults to all years and events and session R.\n",
    "    \"\"\"\n",
    "    def get_event_data(self, **kwargs):\n",
    "        year = kwargs.get('year')\n",
    "        event = kwargs.get('event')\n",
    "        session = kwargs.get('session', 'R')\n",
    "\n",
    "        if year is None and event is None:\n",
    "            # NO YEAR OR EVENT SPECIFIED, GET ALL EVENTS FOR ALL SCHEDULED YEARS\n",
    "            self.event_data_helper_all(session)\n",
    "        elif year is None:\n",
    "            # NO YEAR SPECIFIED, GET ALL EVENTS FOR THE SPECIFIED EVENT\n",
    "            self.event_data_helper_event(event, session)\n",
    "        elif event is None:\n",
    "            # NO EVENT SPECIFIED, GET ALL EVENTS FOR THE SPECIFIED YEAR\n",
    "            self.event_data_helper_year(year, session)\n",
    "        else:\n",
    "            # SPECIFIED YEAR, EVENT,  GET THE SPECIFIED EVENT\n",
    "            data = fastf1.get_session(year, event, session)\n",
    "            data.load()\n",
    "            results = data.results\n",
    "            self.event_data[year][event] = results\n",
    "\n",
    "    def event_data_helper_all(self, session):\n",
    "        events = {}\n",
    "        for i in range(self.start, self.end):\n",
    "            year_stage = {}\n",
    "            if i in self.events:\n",
    "                for event in self.events[i]:\n",
    "                    data = fastf1.get_session(i, event, session)\n",
    "                    data.load()\n",
    "                    results = data.results\n",
    "                    year_stage[event] = results\n",
    "            else:\n",
    "                # SCHEDULE FOR YEAR NOT LOADED\n",
    "                print(f\"Schedules for year {i} not found, please run get_schs() first.\")\n",
    "            events[i] = year_stage\n",
    "        self.event_data = events\n",
    "\n",
    "    def event_data_helper_event(self, event, session):\n",
    "        events = {}\n",
    "        for i in range(self.start, self.end):\n",
    "            year_stage = {}\n",
    "            if i in self.events:\n",
    "                if event in self.events[i]:\n",
    "                    data = fastf1.get_session(i, event, session)\n",
    "                    data.load()\n",
    "                    results = data.results\n",
    "                    year_stage[event] = results\n",
    "                else:\n",
    "                    # EVENT NOT FOUND IN SCHEDULE FOR YEAR\n",
    "                    print(f\"Event {event} not found in year {i}.\")\n",
    "            else:\n",
    "                # SCHEDULE FOR YEAR NOT LOADED\n",
    "                print(f\"Schedule for year {i} not found, check that you have the correct year (data will not be loaded).\")\n",
    "            events[i] = year_stage\n",
    "        self.event_data = events\n",
    "\n",
    "    def event_data_helper_year(self, year, session):\n",
    "        if year in self.events:\n",
    "            year_stage = {}\n",
    "            for event in self.events[year]:\n",
    "                data = fastf1.get_session(year, event, session)\n",
    "                data.load()\n",
    "                results = data.results\n",
    "                year_stage[event] = results\n",
    "            self.event_data[year] = year_stage\n",
    "        else:\n",
    "            # SCHEDULE FOR YEAR NOT LOADED\n",
    "            print(f\"Schedule for year {year} not found, check that you have the correct year (data will not be loaded).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA FOR ENTIRE HYBRID ERA\n",
    "\n",
    "\"\"\"WARING: FASTF1 WILL DOWNLOAD DATA FROM THE INTERNET\n",
    "FASTF1 WILL ALSO OUPUT A LOT OF INFORMATION TO THE CONSOLE; ENSURE OUPUT IS COLLAPSED\n",
    "It is recommended to run the notebook in Google Colab. \n",
    "The notebook is also available on GitHub\"\"\"\n",
    "\n",
    "hybrid_data = FormulaOneDataPreper(2014, 2023)\n",
    "hybrid_data.get_schs()\n",
    "hybrid_data.get_events()\n",
    "hybrid_data.get_event_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2020 Season\n",
    "\n",
    "As we all know the year of 2020 was a precented year for everyone around the world, and Forumla One was no exception. Due to many changes through the year and inconsistancy in data, we will be omitting this year from the data set for this analysis. \n",
    "\n",
    "FastF1 is currently working on interactions with the Formula One API to resolve these issues, you can read more [here](https://github.com/theOehrly/Fast-F1/issues/259)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_2020 = hybrid_data.hybrid_schs[2020]\n",
    "events_2020 = hybrid_data.events[2020]\n",
    "event_data_2020 = hybrid_data.event_data[2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is an example of some of the issues within the 2020 season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_data_2020['Styrian Grand Prix']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's to a quick run through of some data to make sure eveything looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_schedule = hybrid_data.hybrid_schs\n",
    "hybrid_events = hybrid_data.events\n",
    "hybrid_event_data = hybrid_data.event_data\n",
    "\n",
    "# CONVERT DATA TO DATAFRAMES\n",
    "hybrid_events = pd.DataFrame.from_dict(hybrid_events, orient='index')\n",
    "hybrid_event_data = pd.DataFrame.from_dict(hybrid_event_data, orient='index')\n",
    "\n",
    "# DROP 2020\n",
    "hybrid_events = hybrid_events.drop(2020)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_schedule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_event_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_event_data.loc[2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_event_data.loc[2016, 'Canadian Grand Prix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LETS MAKE ANOTHER JOVIAN COMMIT\n",
    "with contextlib.suppress(Exception):\n",
    "    jovian.commit(project=project_name, filename=project_file, files=[\"explore_ergast.py\",\"explore_ergastpy.py\", \"notebook_source\", \"cache\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis and Visualization\n",
    "\n",
    "**TODO** - write some explanation here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Instructions (delete this cell)\n",
    "> \n",
    "> - Compute the mean, sum, range and other interesting statistics for numeric columns\n",
    "> - Explore distributions of numeric columns using histograms etc.\n",
    "> - Explore relationship between columns using scatter plots, bar charts etc.\n",
    "> - Make a note of interesting insights from the exploratory analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by importing`matplotlib.pyplot` and `seaborn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "matplotlib.rcParams['figure.figsize'] = (9, 5)\n",
    "matplotlib.rcParams['figure.facecolor'] = '#00000000'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** - explore flow of teams preformance through hybrid era"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_event_data.loc[2016, 'Canadian Grand Prix'].Points.unique()\n",
    "\n",
    "# every driver that scored points the the 2016 Canadian Grand Prix\n",
    "canada_scores = hybrid_event_data.loc[2016, 'Canadian Grand Prix'][hybrid_event_data.loc[2016, 'Canadian Grand Prix'].Points > 0]\n",
    "# canada_scores\n",
    "canada_scores_teams = canada_scores.groupby('TeamName').Points.sum()\n",
    "canada_scores_teams = canada_scores_teams.sort_values(ascending=False)\n",
    "canada_scores_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores = None\n",
    "\n",
    "for year in hybrid_event_data.index:\n",
    "    # print(year)\n",
    "    for event in hybrid_event_data.columns:\n",
    "        if event in list(hybrid_events.loc[year]):\n",
    "            # print(event)\n",
    "            event_scores = hybrid_event_data.loc[year, event][hybrid_event_data.loc[year, event].Points > 0]\n",
    "            event_scores_teams = event_scores.groupby('TeamName').Points.sum()\n",
    "            # event_scores_teams = event_scores_teams.sort_values(ascending=False)\n",
    "            if total_scores is None:\n",
    "                total_scores = event_scores_teams\n",
    "            else:\n",
    "                total_scores = total_scores.add(event_scores_teams, fill_value=0)\n",
    "\n",
    "total_scores = total_scores.sort_values(ascending=False)\n",
    "total_scores = pd.DataFrame({'Team':total_scores.index, 'Points':total_scores.values})\n",
    "total_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMBINE TEAMS TO THEIR CURRNENT NAMES\n",
    "total_scores = total_scores.replace({'Red Bull': 'Red Bull Racing', 'Alfa Romeo': 'Alfa Romeo Racing ORLEN', 'Marussia': 'Manor Marussia', 'Lotus F1': 'Alpine', 'Renault': 'Alpine', 'Sauber': 'Alfa Romeo Racing ORLEN', 'Force India': 'Aston Martin', 'Racing Point': 'Aston Martin', 'Toro Rosso': 'AlphaTauri'})\n",
    "total_scores = total_scores.groupby('Team').sum().sort_values(by='Points', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_event_data.loc[2022, 'Bahrain Grand Prix'].groupby('TeamName').TeamColor.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_colors = {'Mercedes': '#6cd3bf', \n",
    "'Red Bull Racing': '#1e5bc6', \n",
    "'Ferrari': '#ed1c24',\n",
    "'McLaren': '#f58020', \n",
    "'Aston Martin': '#2d826d', \n",
    "'Alpine': '#2293d1', \n",
    "'Williams': '#37bedd', \n",
    "'AlphaTauri': '#4e7c9b', \n",
    "'Haas F1 Team': '#b6babd', \n",
    "'Alfa Romeo Racing ORLEN': '#b12039',\n",
    "'Alfa Romeo': '#b12039',\n",
    "'Manor Marussia': 'white'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explode = [.2,.2,.2,.2,.2,.2,.2,.2,1,1,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAPH TOTAL SCORES IN A PIE CHART AND GIVE EACH TEAM ITS TEAM COLOUR\n",
    "plt.pie(total_scores.Points, colors=[team_colors[key] for key in total_scores.index], autopct='%1.1f%%', pctdistance=1.3, labeldistance=1.1, textprops={'color':\"r\"}, explode=explode)\n",
    "plt.legend(total_scores.index, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.axis('equal')\n",
    "plt.title('Total Points Scored by Team', color='red')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** - explore flow of drivers preformance thorugh the era"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** - Explore one or more columns by plotting a graph below, and add some explanation about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** - Explore one or more columns by plotting a graph below, and add some explanation about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** - Explore one or more columns by plotting a graph below, and add some explanation about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us save and upload our work to Jovian before continuing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asking and Answering Questions\n",
    "\n",
    "TODO - write some explanation here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Instructions (delete this cell)\n",
    ">\n",
    "> - Ask at least 5 interesting questions about your dataset\n",
    "> - Answer the questions either by computing the results using Numpy/Pandas or by plotting graphs using Matplotlib/Seaborn\n",
    "> - Create new columns, merge multiple dataset and perform grouping/aggregation wherever necessary\n",
    "> - Wherever you're using a library function from Pandas/Numpy/Matplotlib etc. explain briefly what it does\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1: TODO - ask a question here and answer it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2: TODO - ask a question here and answer it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3: TODO - ask a question here and answer it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4: TODO - ask a question here and answer it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5: TODO - ask a question here and answer it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us save and upload our work to Jovian before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferences and Conclusion\n",
    "\n",
    "**TODO** - Write some explanation here: a summary of all the inferences drawn from the analysis, and any conclusions you may have drawn by answering various questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References and Future Work\n",
    "\n",
    "**TODO** - Write some explanation here: ideas for future projects using this dataset, and links to resources you found useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Submission Instructions (delete this cell)\n",
    "> \n",
    "> - Upload your notebook to your Jovian.ml profile using `jovian.commit`.\n",
    "> - **Make a submission here**: https://jovian.ml/learn/data-analysis-with-python-zero-to-pandas/assignment/course-project\n",
    "> - Share your work on the forum: https://jovian.ml/forum/t/course-project-on-exploratory-data-analysis-discuss-and-share-your-work/11684\n",
    "> - Share your work on social media (Twitter, LinkedIn, Telegram etc.) and tag [@JovianML](https://twitter.com/jovianml)\n",
    ">\n",
    "> (Optional) Write a blog post\n",
    "> \n",
    "> - A blog post is a great way to present and showcase your work.  \n",
    "> - Sign up on [Medium.com](https://medium.com) to write a blog post for your project.\n",
    "> - Copy over the explanations from your Jupyter notebook into your blog post, and [embed code cells & outputs](https://medium.com/jovianml/share-and-embed-jupyter-notebooks-online-with-jovian-ml-df709a03064e)\n",
    "> - Check out the Jovian.ml Medium publication for inspiration: https://medium.com/jovianml\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Resources:\n",
    "\n",
    "* [**pyErgast**](https://github.com/weiranyu/pyErgast)**:** Python pandas wrapper for the [Ergast F1 API](http://ergast.com/mrd/). This package allows easy access to the Ergast API for anyone wishing to conduct analysis on Formula 1 data.\n",
    "* [**Ergast API**](http://ergast.com/mrd/)**:** The Ergast Developer API is an experimental [web service](http://en.wikipedia.org/wiki/Web\\_service) which provides a historical record of motor racing data for non-commercial purposes. Please read the [terms and conditions of use](http://ergast.com/mrd/terms). The API provides data for the [Formula One](http://en.wikipedia.org/wiki/Formula\\_One)series, from the beginning of the world championships in 1950.\n",
    "\n",
    "#### &#x20;                                                                                          Usage\n",
    "\n",
    "Use of the Ergast API is completely free, but you are welcome to [contribute to the annual running costs](https://liberapay.com/ergast). Any contributions above the actual costs will be donated to the [Grand Prix Trust](https://www.grandprixtrust.com/).\n",
    "\n",
    "<figure><img src=\"https://liberapay.com/assets/widgets/donate.svg\" alt=\"\"><figcaption></figcaption></figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jovian.commit(project=project_name, filename=project_file, files=[\"README.md\", \"SUMMARY.md\", \"explore_ergast.py\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ce5d4c5ce0eae8759d521230ff7b88377fa62fb91656e5c2966f4bb1fdd362b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
