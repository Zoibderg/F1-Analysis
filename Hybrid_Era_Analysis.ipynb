{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# üèé Formula 1 'Hybrid Era' Analysis\n",
    "\n",
    "<img src=\"notebook_source/JPG-RGB-F1_70_Number_HotRed_Standard_RGB-1024x302.jpg\">\n",
    "\n",
    "### About the Dataset\n",
    "\n",
    "#### Context\n",
    "\n",
    "Formula 1 (a.k.a. F1 or Formula One) is the highest class of single-seater auto racing sanctioned by the F√©d√©ration Internationale de l'Automobile (FIA) and owned by the Formula One Group. The FIA Formula One World Championship has been one of the premier forms of racing around the world since its inaugural season in 1950. The word \"formula\" in the name refers to the set of rules to which all participants' cars must conform. A Formula One season consists of a series of races, known as Grands Prix, which take place worldwide on purpose-built circuits and on public roads.\n",
    "\n",
    "#### Content\n",
    "\n",
    "The dataset consists of all information on the Formula 1 races, drivers, constructors, qualifying, circuits, lap times, pit stops, championships from 1950 till the latest 2021 season.\n",
    "\n",
    "## What is the Hybird Era?\n",
    "\n",
    "### 2014-2021\n",
    "\n",
    "The year 2014 ushered in the most significant rule changes in F1 history, with normally aspirated, 2.4-liter V8 engines replaced by new, 1.6-liter turbocharged V6 ‚Äúpower units‚Äù (no longer officially called engines) integrated with complex, hybrid energy recovery systems (ERS) that FIA claimed ‚Äúgave the sport a much cleaner and greener image more relevant to developing road car technologies.‚Äù&#x20;\n",
    "\n",
    "The new formula allows turbocharged engines, which last appeared in 1988. These have their efficiency improved through turbo-compounding by recovering energy from exhaust gases. The original proposal for four-cylinder turbocharged engines was not welcomed by the racing teams, in particular Ferrari. A compromise was reached, allowing V6 forced induction engines instead. The engines rarely exceed 12,000 rpm during qualifying and race, due to the new fuel flow restrictions.\n",
    "\n",
    "Energy recovery systems such as KERS had a boost of 160 hp (120 kW) and 2 megajoules per lap. KERS was renamed Motor Generator Unit‚ÄìKinetic (MGU-K). Heat energyrecovery systems were also allowed, under the name Motor Generator Unit‚ÄìHeat (MGU-H)\n",
    "\n",
    "The 2015 season was an improvement on 2014, adding about 30‚Äì50 hp (20‚Äì40 kW) to most engines, the Mercedes engine being the most powerful with 870 hp (649 kW). In 2019, Renault's engine was claimed to have hit 1,000 hp in qualifying trim.\n",
    "\n",
    "### 2022\n",
    "\n",
    "In 2017, the FIA began negotiations with existing constructors and potential new manufacturers over the next generation of engines with a projected introduction date of 2021 but delayed to 2022 due to the effects of the COVID-19 pandemic. The initial proposal was designed to simplify engine designs, cut costs, promote new entries and address criticisms directed at the 2014 generation of engines. It called for the 1.6 L V6 configuration to be retained, but abandoned the complex Motor Generator Unit‚ÄìHeat (MGU-H) system. The Motor Generator Unit‚ÄìKinetic (MGU-K) would be more powerful, with a greater emphasis on driver deployment and a more flexible introduction to allow for tactical use.&#x20;\n",
    "\n",
    "The proposal also called for the introduction of standardised components and design parameters to make components produced by all manufacturers compatible with one another in a system dubbed \"plug in and play\". A further proposal to allow four-wheel drive cars was also made, with the front axle driven by an MGU-K unit‚Äîas opposed to the traditional driveshaft‚Äîthat functioned independently of the MGU-K providing power to the rear axle, mirroring the system developed by Porsche for the 919 Hybrid race car.\n",
    "\n",
    "However, mostly due to no engine supplier applying for F1 entry in 2021 and 2022, abolishment of the MGU-H, a more powerful MGU-K and a four-wheel drive system were all shelved with the possibility of their re-introduction for 2026. Instead, the teams and FIA agreed to a radical change in body/chassis aerodynamics to promote more battles on the course at closer distances to each other. They further agreed to an increase in alcohol content from 5.75% to 10% of fuel, and to implement a freeze on power unit design for 2022-2025, with the ICE, turbocharger and MGU-H being frozen on March 1st and the energy store, MGU-K and control electronics being frozen on September 1st during the 2022 season. Honda, the outgoing engine supplier in 2021, was keen to keep the MGU-H, and Red Bull, who took over the engine production project, backed that opinion. The 4WD system was planned to be based on Porsche 919 Hybrid system, but Porsche ended up not becoming an F1 engine supplier for 2021-2022."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### How to run the code\n",
    "\n",
    "This is an executable [*Jupyter notebook*](https://jupyter.org) hosted on [Jovian.ml](https://www.jovian.ml), a platform for sharing data science projects. You can run and experiment with the code in a couple of ways: *using free online resources* (recommended) or *on your own computer*.\n",
    "\n",
    "#### Option 1: Running using free online resources (1-click, recommended)\n",
    "\n",
    "The easiest way to start executing this notebook is to click the \"Run\" button at the top of this page, and select \"Run on Binder\". This will run the notebook on [mybinder.org](https://mybinder.org), a free online service for running Jupyter notebooks. You can also select \"Run on Colab\" or \"Run on Kaggle\".\n",
    "\n",
    "\n",
    "#### Option 2: Running on your computer locally\n",
    "\n",
    "1. Install Conda by [following these instructions](https://conda.io/projects/conda/en/latest/user-guide/install/index.html). Add Conda binaries to your system `PATH`, so you can use the `conda` command on your terminal.\n",
    "\n",
    "2. Create a Conda environment and install the required libraries by running these commands on the terminal:\n",
    "\n",
    "```\n",
    "conda create -n zerotopandas -y python=3.8 \n",
    "conda activate zerotopandas\n",
    "pip install jovian jupyter numpy pandas matplotlib seaborn opendatasets --upgrade\n",
    "```\n",
    "\n",
    "3. Press the \"Clone\" button above to copy the command for downloading the notebook, and run it on the terminal. This will create a new directory and download the notebook. The command will look something like this:\n",
    "\n",
    "```\n",
    "jovian clone notebook-owner/notebook-id\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "4. Enter the newly created directory using `cd directory-name` and start the Jupyter notebook.\n",
    "\n",
    "```\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "You can now access Jupyter's web interface by clicking the link that shows up on the terminal or by visiting http://localhost:8888 on your browser. Click on the notebook file (it has a `.ipynb` extension) to open it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the Dataset\n",
    "\n",
    "We will be using pyergast to for access to the Formula 1 database provided by Ergast API. Pyergast gives us direct access to the database, with no need to downlowd a CSV or any other files. \n",
    "\n",
    "The \"explore_pyergast.py\" file will dive into pyergast's features and do some minor exploration in the data to gain familirity with the pyergast commands. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip --quiet\n",
    "!pip install pyergast --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyergast requires both numpy and pandas\n",
    "from unittest import result\n",
    "from IPython.utils import io\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pprint as pp\n",
    "from timple.timedelta import strftimedelta\n",
    "import fastf1\n",
    "import fastf1.plotting as plotting\n",
    "from fastf1.core import Laps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us save and upload our work to Jovian before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"hybrid-era-analysis\"\n",
    "project_file = \"Hybrid_Era_Analysis.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jovian --upgrade -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "if (window.IPython && IPython.notebook.kernel) IPython.notebook.kernel.execute('jovian.utils.jupyter.get_notebook_name_saved = lambda: \"' + IPython.notebook.notebook_name + '\"')",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"zoibderg/hybrid-era-analysis\" on https://jovian.ai/\u001b[0m\n",
      "[jovian] Uploading additional files...\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ai/zoibderg/hybrid-era-analysis\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ai/zoibderg/hybrid-era-analysis'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit(project=project_name, filename=project_file, files=[\"explore_ergast.py\", \"notebook_source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation and Cleaning\n",
    "\n",
    "**TODO** - Write some explanation here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Instructions (delete this cell):\n",
    ">\n",
    "> - Load the dataset into a data frame using Pandas\n",
    "> - Explore the number of rows & columns, ranges of values etc.\n",
    "> - Handle missing, incorrect and invalid data\n",
    "> - Perform any additional steps (parsing dates, creating additional columns, merging multiple dataset etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Japanese Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '11', '16', '31', '44', '5', '14', '63', '6', '4', '3', '18', '22', '20', '77', '24', '47', '10', '55', '23']\n",
      "core           INFO \tLoading data for Hungarian Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/austintesch/Documents/GitHub/F1_HE_Analysis/Hybrid_Era_Analysis.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/austintesch/Documents/GitHub/F1_HE_Analysis/Hybrid_Era_Analysis.ipynb#X15sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m enable_cache()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/austintesch/Documents/GitHub/F1_HE_Analysis/Hybrid_Era_Analysis.ipynb#X15sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m events \u001b[39m=\u001b[39m load_hybrid_events()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/austintesch/Documents/GitHub/F1_HE_Analysis/Hybrid_Era_Analysis.ipynb#X15sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m load_hybrid_data(events)\n",
      "\u001b[1;32m/Users/austintesch/Documents/GitHub/F1_HE_Analysis/Hybrid_Era_Analysis.ipynb Cell 13\u001b[0m in \u001b[0;36mload_hybrid_data\u001b[0;34m(events)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/austintesch/Documents/GitHub/F1_HE_Analysis/Hybrid_Era_Analysis.ipynb#X15sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mfor\u001b[39;00m event \u001b[39min\u001b[39;00m value:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/austintesch/Documents/GitHub/F1_HE_Analysis/Hybrid_Era_Analysis.ipynb#X15sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     gp \u001b[39m=\u001b[39m fastf1\u001b[39m.\u001b[39mget_session(\u001b[39m2022\u001b[39m, event, \u001b[39m'\u001b[39m\u001b[39mR\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/austintesch/Documents/GitHub/F1_HE_Analysis/Hybrid_Era_Analysis.ipynb#X15sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     gp\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/austintesch/Documents/GitHub/F1_HE_Analysis/Hybrid_Era_Analysis.ipynb#X15sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     result \u001b[39m=\u001b[39m gp\u001b[39m.\u001b[39mresults\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1175\u001b[0m, in \u001b[0;36mSession.load\u001b[0;34m(self, laps, telemetry, weather, messages, livedata)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[39mif\u001b[39;00m laps:\n\u001b[1;32m   1174\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1175\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_laps_data(livedata)\n\u001b[1;32m   1176\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m   1177\u001b[0m         logging\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mFailed to load lap data!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1470\u001b[0m, in \u001b[0;36mSession._load_laps_data\u001b[0;34m(self, livedata)\u001b[0m\n\u001b[1;32m   1468\u001b[0m     logging\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mCould not load any valid session status information!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1469\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_laps \u001b[39m=\u001b[39m Laps(laps, session\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n\u001b[0;32m-> 1470\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_lap_accuracy()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1518\u001b[0m, in \u001b[0;36mSession._check_lap_accuracy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1516\u001b[0m prev_lap \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m integrity_errors \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1518\u001b[0m \u001b[39mfor\u001b[39;00m _, lap \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlaps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlaps[\u001b[39m'\u001b[39m\u001b[39mDriverNumber\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m drv]\u001b[39m.\u001b[39miterrows():\n\u001b[1;32m   1519\u001b[0m     \u001b[39m# require existence, non-existence and specific values for some variables\u001b[39;00m\n\u001b[1;32m   1520\u001b[0m     check_1 \u001b[39m=\u001b[39m (pd\u001b[39m.\u001b[39misnull(lap[\u001b[39m'\u001b[39m\u001b[39mPitInTime\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m   1521\u001b[0m                \u001b[39m&\u001b[39m pd\u001b[39m.\u001b[39misnull(lap[\u001b[39m'\u001b[39m\u001b[39mPitOutTime\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m   1522\u001b[0m                \u001b[39m&\u001b[39m (lap[\u001b[39m'\u001b[39m\u001b[39mTrackStatus\u001b[39m\u001b[39m'\u001b[39m] \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39m1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m2\u001b[39m\u001b[39m'\u001b[39m))  \u001b[39m# slightly paranoid, allow only green and yellow flag\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                \u001b[39m&\u001b[39m (\u001b[39mnot\u001b[39;00m pd\u001b[39m.\u001b[39misnull(lap[\u001b[39m'\u001b[39m\u001b[39mSector2Time\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[1;32m   1526\u001b[0m                \u001b[39m&\u001b[39m (\u001b[39mnot\u001b[39;00m pd\u001b[39m.\u001b[39misnull(lap[\u001b[39m'\u001b[39m\u001b[39mSector3Time\u001b[39m\u001b[39m'\u001b[39m])))\n\u001b[1;32m   1528\u001b[0m     \u001b[39mif\u001b[39;00m check_1:  \u001b[39m# only do check 2 if all necessary values for this check are even available\u001b[39;00m\n\u001b[1;32m   1529\u001b[0m         \u001b[39m# sum of sector times should be almost equal to lap time (tolerance 3ms)\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:1323\u001b[0m, in \u001b[0;36mDataFrame.iterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1321\u001b[0m columns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m   1322\u001b[0m klass \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor_sliced\n\u001b[0;32m-> 1323\u001b[0m \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalues):\n\u001b[1;32m   1324\u001b[0m     s \u001b[39m=\u001b[39m klass(v, index\u001b[39m=\u001b[39mcolumns, name\u001b[39m=\u001b[39mk)\n\u001b[1;32m   1325\u001b[0m     \u001b[39myield\u001b[39;00m k, s\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:10877\u001b[0m, in \u001b[0;36mDataFrame.values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m  10804\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m  10805\u001b[0m \u001b[39mReturn a Numpy representation of the DataFrame.\u001b[39;00m\n\u001b[1;32m  10806\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10874\u001b[0m \u001b[39m       ['monkey', nan, None]], dtype=object)\u001b[39;00m\n\u001b[1;32m  10875\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m  10876\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m> 10877\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mas_array()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/managers.py:1589\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1587\u001b[0m             arr \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1588\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1589\u001b[0m     arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interleave(dtype\u001b[39m=\u001b[39;49mdtype, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[1;32m   1590\u001b[0m     \u001b[39m# The underlying data was copied within _interleave\u001b[39;00m\n\u001b[1;32m   1591\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/managers.py:1636\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1634\u001b[0m \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks:\n\u001b[1;32m   1635\u001b[0m     rl \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39mmgr_locs\n\u001b[0;32m-> 1636\u001b[0m     arr \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39;49mget_values(dtype)\n\u001b[1;32m   1637\u001b[0m     result[rl\u001b[39m.\u001b[39mindexer] \u001b[39m=\u001b[39m arr\n\u001b[1;32m   1638\u001b[0m     itemmask[rl\u001b[39m.\u001b[39mindexer] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/blocks.py:1451\u001b[0m, in \u001b[0;36mEABackedBlock.get_values\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1449\u001b[0m values: ArrayLike \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\n\u001b[1;32m   1450\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39m==\u001b[39m _dtype_obj:\n\u001b[0;32m-> 1451\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39;49mastype(\u001b[39mobject\u001b[39;49m)\n\u001b[1;32m   1452\u001b[0m \u001b[39m# TODO(EA2D): reshape not needed with 2D EAs\u001b[39;00m\n\u001b[1;32m   1453\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray(values)\u001b[39m.\u001b[39mreshape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/timedeltas.py:359\u001b[0m, in \u001b[0;36mTimedeltaArray.astype\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[39mif\u001b[39;00m dtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mm\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    357\u001b[0m     \u001b[39mreturn\u001b[39;00m astype_td64_unit_conversion(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ndarray, dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m--> 359\u001b[0m \u001b[39mreturn\u001b[39;00m dtl\u001b[39m.\u001b[39;49mDatetimeLikeArrayMixin\u001b[39m.\u001b[39;49mastype(\u001b[39mself\u001b[39;49m, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/datetimelike.py:424\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin.astype\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m    415\u001b[0m         converted \u001b[39m=\u001b[39m ints_to_pydatetime(\n\u001b[1;32m    416\u001b[0m             i8data,\n\u001b[1;32m    417\u001b[0m             \u001b[39m# error: \"DatetimeLikeArrayMixin\" has no attribute \"tz\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    420\u001b[0m             box\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtimestamp\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    421\u001b[0m         )\n\u001b[1;32m    422\u001b[0m         \u001b[39mreturn\u001b[39;00m converted\u001b[39m.\u001b[39mreshape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape)\n\u001b[0;32m--> 424\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_box_values(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49masi8\u001b[39m.\u001b[39;49mravel())\u001b[39m.\u001b[39mreshape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    426\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[1;32m    427\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/datetimelike.py:272\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin._box_values\u001b[0;34m(self, values)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_box_values\u001b[39m(\u001b[39mself\u001b[39m, values) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m    269\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[39m    apply box func to passed values\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 272\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49mmap_infer(values, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_box_func, convert\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/timedeltas.py:152\u001b[0m, in \u001b[0;36mTimedeltaArray._box_func\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    141\u001b[0m _datetimelike_methods: \u001b[39mlist\u001b[39m[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m [\n\u001b[1;32m    142\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mto_pytimedelta\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    143\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtotal_seconds\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mceil\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    147\u001b[0m ]\n\u001b[1;32m    149\u001b[0m \u001b[39m# Note: ndim must be defined to ensure NaT.__richcmp__(TimedeltaArray)\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[39m#  operates pointwise.\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_box_func\u001b[39m(\u001b[39mself\u001b[39m, x) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Timedelta \u001b[39m|\u001b[39m NaTType:\n\u001b[1;32m    153\u001b[0m     \u001b[39mreturn\u001b[39;00m Timedelta(x, unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mns\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    155\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    156\u001b[0m \u001b[39m# error: Return type \"dtype\" of \"dtype\" incompatible with return type\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39m# \"ExtensionDtype\" in supertype \"ExtensionArray\"\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdtype\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mdtype:  \u001b[39m# type: ignore[override]\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "WARING: This is a very long notebook. \n",
    "It is recommended to run the notebook in Google Colab. \n",
    "The notebook is also available on GitHub:\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "LOAD HYBRID ERA DATA\n",
    "Gather schedule\n",
    "Gather telemetry\n",
    "\"\"\"\n",
    "def enable_cache():\n",
    "    fastf1.Cache.enable_cache('./cache')  # enable data caching\n",
    "\n",
    "def load_hybrid_events():\n",
    "    # ALL EVENTS FROM 2014-2022, EXCLUDING TESTING\n",
    "    hybrid_era_events = {}\n",
    "    for i in range(2014, 2023):\n",
    "        sch = fastf1.get_event_schedule(i, include_testing=False)\n",
    "        hybrid_era_events[i] = sch\n",
    "\n",
    "    #print(hybrid_era_events)\n",
    "    return hybrid_era_events\n",
    "\n",
    "def load_hybrid_data(events):\n",
    "    # LOAD DATA FOR ALL RACE EVENTS\n",
    "    # MAY INCLUDE OTHER EVENTS, BUT FOR NOW, THIS IS FINE\n",
    "    for value in events.values():\n",
    "        for event in value:\n",
    "            gp = fastf1.get_session(2022, event, 'R')\n",
    "            gp.load()\n",
    "            result = gp.results\n",
    "            # print(result)\n",
    "\n",
    "with io.capture_output() as captured:\n",
    "    enable_cache()\n",
    "    events = load_hybrid_events()\n",
    "    load_hybrid_data(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"LOAD HYBRID ERA DATA\n",
    "Gather schedule\n",
    "Gather telemetry\n",
    "\"\"\"\n",
    "\n",
    "from distutils.fancy_getopt import fancy_getopt\n",
    "\n",
    "\n",
    "fastf1.Cache.enable_cache('./cache')  # enable data caching\n",
    "\n",
    "# ALL EVENTS FROM 2014-2022, EXCLUDING TESTING\n",
    "hybrid_era_events = {}\n",
    "for i in range(2014, 2023):\n",
    "    sch = fastf1.get_event_schedule(i, include_testing=False)\n",
    "    hybrid_era_events[i] = sch\n",
    "#print(hybrid_era_events)\n",
    "\n",
    "# LOAD DATA FOR ALL RACE EVENTS\n",
    "# MAY INCLUDE OTHER EVENTS, BUT FOR NOW, THIS IS FINE\n",
    "for value in hybrid_era_events.values():\n",
    "    for event in value:\n",
    "        gp = fastf1.get_session(2022, event, 'R')\n",
    "        gp.load()\n",
    "        result = gp.results\n",
    "        # print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Attempting to save notebook..\u001b[0m\n",
      "[jovian] Updating notebook \"aakashns/zerotopandas-course-project-starter\" on https://jovian.ml/\u001b[0m\n",
      "[jovian] Uploading notebook..\u001b[0m\n",
      "[jovian] Capturing environment..\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ml/aakashns/zerotopandas-course-project-starter\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ml/aakashns/zerotopandas-course-project-starter'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis and Visualization\n",
    "\n",
    "**TODO** - write some explanation here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Instructions (delete this cell)\n",
    "> \n",
    "> - Compute the mean, sum, range and other interesting statistics for numeric columns\n",
    "> - Explore distributions of numeric columns using histograms etc.\n",
    "> - Explore relationship between columns using scatter plots, bar charts etc.\n",
    "> - Make a note of interesting insights from the exploratory analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by importing`matplotlib.pyplot` and `seaborn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "matplotlib.rcParams['figure.figsize'] = (9, 5)\n",
    "matplotlib.rcParams['figure.facecolor'] = '#00000000'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** - Explore one or more columns by plotting a graph below, and add some explanation about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** - Explore one or more columns by plotting a graph below, and add some explanation about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** - Explore one or more columns by plotting a graph below, and add some explanation about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** - Explore one or more columns by plotting a graph below, and add some explanation about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** - Explore one or more columns by plotting a graph below, and add some explanation about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us save and upload our work to Jovian before continuing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Attempting to save notebook..\u001b[0m\n",
      "[jovian] Updating notebook \"aakashns/zerotopandas-course-project-starter\" on https://jovian.ml/\u001b[0m\n",
      "[jovian] Uploading notebook..\u001b[0m\n",
      "[jovian] Capturing environment..\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ml/aakashns/zerotopandas-course-project-starter\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ml/aakashns/zerotopandas-course-project-starter'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asking and Answering Questions\n",
    "\n",
    "TODO - write some explanation here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Instructions (delete this cell)\n",
    ">\n",
    "> - Ask at least 5 interesting questions about your dataset\n",
    "> - Answer the questions either by computing the results using Numpy/Pandas or by plotting graphs using Matplotlib/Seaborn\n",
    "> - Create new columns, merge multiple dataset and perform grouping/aggregation wherever necessary\n",
    "> - Wherever you're using a library function from Pandas/Numpy/Matplotlib etc. explain briefly what it does\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1: TODO - ask a question here and answer it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2: TODO - ask a question here and answer it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3: TODO - ask a question here and answer it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4: TODO - ask a question here and answer it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5: TODO - ask a question here and answer it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us save and upload our work to Jovian before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Attempting to save notebook..\u001b[0m\n",
      "[jovian] Updating notebook \"aakashns/zerotopandas-course-project-starter\" on https://jovian.ml/\u001b[0m\n",
      "[jovian] Uploading notebook..\u001b[0m\n",
      "[jovian] Capturing environment..\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ml/aakashns/zerotopandas-course-project-starter\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ml/aakashns/zerotopandas-course-project-starter'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferences and Conclusion\n",
    "\n",
    "**TODO** - Write some explanation here: a summary of all the inferences drawn from the analysis, and any conclusions you may have drawn by answering various questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Attempting to save notebook..\u001b[0m\n",
      "[jovian] Updating notebook \"aakashns/zerotopandas-course-project-starter\" on https://jovian.ml/\u001b[0m\n",
      "[jovian] Uploading notebook..\u001b[0m\n",
      "[jovian] Capturing environment..\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ml/aakashns/zerotopandas-course-project-starter\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ml/aakashns/zerotopandas-course-project-starter'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References and Future Work\n",
    "\n",
    "**TODO** - Write some explanation here: ideas for future projects using this dataset, and links to resources you found useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Submission Instructions (delete this cell)\n",
    "> \n",
    "> - Upload your notebook to your Jovian.ml profile using `jovian.commit`.\n",
    "> - **Make a submission here**: https://jovian.ml/learn/data-analysis-with-python-zero-to-pandas/assignment/course-project\n",
    "> - Share your work on the forum: https://jovian.ml/forum/t/course-project-on-exploratory-data-analysis-discuss-and-share-your-work/11684\n",
    "> - Share your work on social media (Twitter, LinkedIn, Telegram etc.) and tag [@JovianML](https://twitter.com/jovianml)\n",
    ">\n",
    "> (Optional) Write a blog post\n",
    "> \n",
    "> - A blog post is a great way to present and showcase your work.  \n",
    "> - Sign up on [Medium.com](https://medium.com) to write a blog post for your project.\n",
    "> - Copy over the explanations from your Jupyter notebook into your blog post, and [embed code cells & outputs](https://medium.com/jovianml/share-and-embed-jupyter-notebooks-online-with-jovian-ml-df709a03064e)\n",
    "> - Check out the Jovian.ml Medium publication for inspiration: https://medium.com/jovianml\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Resources:\n",
    "\n",
    "* [**pyErgast**](https://github.com/weiranyu/pyErgast)**:** Python pandas wrapper for the [Ergast F1 API](http://ergast.com/mrd/). This package allows easy access to the Ergast API for anyone wishing to conduct analysis on Formula 1 data.\n",
    "* [**Ergast API**](http://ergast.com/mrd/)**:** The Ergast Developer API is an experimental [web service](http://en.wikipedia.org/wiki/Web\\_service) which provides a historical record of motor racing data for non-commercial purposes. Please read the [terms and conditions of use](http://ergast.com/mrd/terms). The API provides data for the [Formula One](http://en.wikipedia.org/wiki/Formula\\_One)series, from the beginning of the world championships in 1950.\n",
    "\n",
    "#### &#x20;                                                                                          Usage\n",
    "\n",
    "Use of the Ergast API is completely free, but you are welcome to [contribute to the annual running costs](https://liberapay.com/ergast). Any contributions above the actual costs will be donated to the [Grand Prix Trust](https://www.grandprixtrust.com/).\n",
    "\n",
    "<figure><img src=\"https://liberapay.com/assets/widgets/donate.svg\" alt=\"\"><figcaption></figcaption></figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"zoibderg/hybrid-era-analysis\" on https://jovian.ai/\u001b[0m\n",
      "[jovian] Uploading additional files...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m[jovian] Error: File upload failed: (HTTP 400) Invalid filename or extension (README.md)\u001b[0m\n",
      "\u001b[31m[jovian] Error: File upload failed: (HTTP 400) Invalid filename or extension (SUMMARY.md)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Committed successfully! https://jovian.ai/zoibderg/hybrid-era-analysis\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ai/zoibderg/hybrid-era-analysis'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit(project=project_name, filename=project_file, files=[\"README.md\", \"SUMMARY.md\", \"explore_ergast.py\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ce5d4c5ce0eae8759d521230ff7b88377fa62fb91656e5c2966f4bb1fdd362b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
